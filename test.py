# test_rag.py

from rag_engine.embedding import get_embedding
from rag_engine.vector_store import query_vector_store
from rag_engine.llm import call_llm, count_tokens, suggest_followups
from rag_engine.reranker import rerank_results
import os


def main():
    print("=== Domain-AI Copilot (Phase 2) ===")
    while True:
        query = input("\nüîç Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n: ")
        if query.lower() in ["exit", "quit"]:
            break

        query_embedding = get_embedding(query)
        top_k_results = query_vector_store(query_embedding, top_k=10)

        # Re-rank c√°c k·∫øt qu·∫£
        reranked = rerank_results(query, top_k_results, top_n=5)

        print("\nüìÑ Top 5 t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t (sau khi rerank):")
        context = ""
        for i, doc in enumerate(reranked):
            metadata = doc.payload or {}
            content = metadata.get("text", "<no content>")
            score = doc.score
            source = metadata.get("source", "unknown")
            chunk_id = metadata.get("chunk_id", "?")
            print(f"[{i+1}] (Score: {score:.4f}) - {source} [Chunk #{chunk_id}]\n{content}\n")
            context += content + "\n"

        token_count = count_tokens(context)
        print(f"üß† T·ªïng s·ªë tokens d√πng l√†m context: {token_count}")

        final_prompt = f"Tr·∫£ l·ªùi c√¢u h·ªèi sau d·ª±a v√†o th√¥ng tin sau:\n---\n{context}\n---\nC√¢u h·ªèi: {query}"
        answer = call_llm(final_prompt)

        print("\nü§ñ Tr·∫£ l·ªùi:")
        print(answer)

        suggestions = suggest_followups(answer)
        print("\nüí° G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo:")
        for i, sug in enumerate(suggestions, 1):
            print(f"{i}. {sug}")


if __name__ == "__main__":
    main()
